# -*- coding: utf-8 -*-

BOT_NAME = 'crawler'

SPIDER_MODULES = ['spiders']
NEWSPIDER_MODULE = 'spiders'

USER_AGENT = (
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) '
    'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36')

CONCURRENT_REQUESTS = 64
CONCURRENT_REQUESTS_PER_DOMAIN = 2
DOWNLOAD_TIMEOUT = 15

DEPTH_PRIORITY = 1
SCHEDULER_DISK_QUEUE = 'scrapy.squeues.PickleFifoDiskQueue'
SCHEDULER_MEMORY_QUEUE = 'scrapy.squeues.FifoMemoryQueue'

COOKIES_ENABLED = False
TELNETCONSOLE_ENABLED = False
RETRY_ENABLED = False

DEFAULT_REQUEST_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en',
}

FEED_EXPORTERS = {
    'jl.gz': 'exports.JsonLinesGzipItemExporter',
}
DOWNLOADER_MIDDLEWARES = {
    'middleware.Gather404Middleware': 450,
}

LOG_LEVEL = 'INFO'

MAX_DOMAIN_REQUESTS = 7

PROB_404 = 0.3

try:
    from local_settings import *  # NOQA
except ImportError:
    pass
